{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f71d4003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69c77b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (2.3.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (4.67.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (1.2.1)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (4.25.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (3.10.7)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from jsonschema) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from jsonschema) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from jsonschema) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from jsonschema) (0.30.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (2.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from openai) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from openai) (2.12.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas tqdm python-dotenv jsonschema matplotlib\n",
    "\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ec70113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from jsonschema import Draft7Validator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d60a75b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tqdm\n",
      "Version: 4.67.1\n",
      "Summary: Fast, Extensible Progress Meter\n",
      "Home-page: https://tqdm.github.io\n",
      "Author: \n",
      "Author-email: \n",
      "License: MPL-2.0 AND MIT\n",
      "Location: C:\\Users\\Samta sakha\\AppData\\Roaming\\Python\\Python314\\site-packages\n",
      "Requires: colorama\n",
      "Required-by: google-generativeai, openai\n"
     ]
    }
   ],
   "source": [
    "!pip show tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5c294d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from jsonschema import Draft7Validator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cde6544f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python314\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "291db6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'C:\\Program' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'C:\\Program' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6fcd37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (25.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "exe = f'\"{sys.executable}\"'\n",
    "!{exe} -m pip install --upgrade pip\n",
    "!{exe} -m pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "307f85cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from jsonschema import Draft7Validator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d0da951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provider: openai\n"
     ]
    }
   ],
   "source": [
    "# PROVIDER: choose one of 'openai', 'gemini', 'openrouter'\n",
    "LLM_PROVIDER = 'openai'  # change to 'gemini' or 'openrouter' or 'auto' as needed\n",
    "\n",
    "# Set environment variables or paste keys here (better: use .env)\n",
    "# Example:\n",
    "# os.environ['OPENAI_API_KEY'] = \"sk-....\"\n",
    "# os.environ['OPENROUTER_API_KEY'] = \"or-...\"\n",
    "# os.environ['GEMINI_API_KEY'] = \"GEMINI_KEY\"\n",
    "\n",
    "print(\"Provider:\", LLM_PROVIDER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "168b4571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rows: 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>QnAzW6KMSciUcuJ20oI3Bw</td>\n",
       "      <td>2010-12-30</td>\n",
       "      <td>21Nfgtnns8gZuzNfg7c_QQ</td>\n",
       "      <td>4</td>\n",
       "      <td>Great place for lunch, transport yourself back...</td>\n",
       "      <td>review</td>\n",
       "      <td>uzWTAgkONAZd5NrfP9XXlQ</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>E4b5OC_6mZ0V7B6Nyjncsg</td>\n",
       "      <td>2012-01-13</td>\n",
       "      <td>VdD-2K_izVXf9nd912TkXg</td>\n",
       "      <td>2</td>\n",
       "      <td>My girlfriend liked this place more than I did...</td>\n",
       "      <td>review</td>\n",
       "      <td>-V3CXSxnUzjkLVqi1xGrkA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Exx5ffvnmk4MrTyCkPRuug</td>\n",
       "      <td>2012-07-24</td>\n",
       "      <td>2YfYYOjwd_yOHxEuv-9Sqg</td>\n",
       "      <td>3</td>\n",
       "      <td>Other then the chips and salsa (5 stars for sa...</td>\n",
       "      <td>review</td>\n",
       "      <td>BtQVxFotHFK3T2FtIrBWmg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>RqbSeoeqXTwts5pfhw7nJg</td>\n",
       "      <td>2009-04-24</td>\n",
       "      <td>gjtWdiEMMfoOTCfdd3hPmA</td>\n",
       "      <td>4</td>\n",
       "      <td>Man, if these guys were trying to replicate a ...</td>\n",
       "      <td>review</td>\n",
       "      <td>dYtkphUrU7S2_bjif6k2uA</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>I4bSn5gXsHuSPu7L-d_8nQ</td>\n",
       "      <td>2012-12-04</td>\n",
       "      <td>EI3YXHKCwAIrEj18OVNg-g</td>\n",
       "      <td>5</td>\n",
       "      <td>Fun, with caps if I did that sort of thing. Th...</td>\n",
       "      <td>review</td>\n",
       "      <td>k99cC9QpbUXlGRWwxEe93w</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                business_id        date               review_id  stars  \\\n",
       "0    9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1    ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2    6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3    _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4    6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "..                      ...         ...                     ...    ...   \n",
       "195  QnAzW6KMSciUcuJ20oI3Bw  2010-12-30  21Nfgtnns8gZuzNfg7c_QQ      4   \n",
       "196  E4b5OC_6mZ0V7B6Nyjncsg  2012-01-13  VdD-2K_izVXf9nd912TkXg      2   \n",
       "197  Exx5ffvnmk4MrTyCkPRuug  2012-07-24  2YfYYOjwd_yOHxEuv-9Sqg      3   \n",
       "198  RqbSeoeqXTwts5pfhw7nJg  2009-04-24  gjtWdiEMMfoOTCfdd3hPmA      4   \n",
       "199  I4bSn5gXsHuSPu7L-d_8nQ  2012-12-04  EI3YXHKCwAIrEj18OVNg-g      5   \n",
       "\n",
       "                                                  text    type  \\\n",
       "0    My wife took me here on my birthday for breakf...  review   \n",
       "1    I have no idea why some people give bad review...  review   \n",
       "2    love the gyro plate. Rice is so good and I als...  review   \n",
       "3    Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4    General Manager Scott Petello is a good egg!!!...  review   \n",
       "..                                                 ...     ...   \n",
       "195  Great place for lunch, transport yourself back...  review   \n",
       "196  My girlfriend liked this place more than I did...  review   \n",
       "197  Other then the chips and salsa (5 stars for sa...  review   \n",
       "198  Man, if these guys were trying to replicate a ...  review   \n",
       "199  Fun, with caps if I did that sort of thing. Th...  review   \n",
       "\n",
       "                    user_id  cool  useful  funny  \n",
       "0    rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1    0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2    0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3    uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4    vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  \n",
       "..                      ...   ...     ...    ...  \n",
       "195  uzWTAgkONAZd5NrfP9XXlQ     0       1      0  \n",
       "196  -V3CXSxnUzjkLVqi1xGrkA     0       0      0  \n",
       "197  BtQVxFotHFK3T2FtIrBWmg     1       1      0  \n",
       "198  dYtkphUrU7S2_bjif6k2uA     2       3      3  \n",
       "199  k99cC9QpbUXlGRWwxEe93w     2       2      2  \n",
       "\n",
       "[200 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POSSIBLE_PATHS = [\n",
    "    r\"C:\\Users\\Samta sakha\\OneDrive\\Desktop\\projects2\\Fynd\\yelp.csv.zip\"\n",
    "]\n",
    "\n",
    "data_path = None\n",
    "for p in POSSIBLE_PATHS:\n",
    "    if Path(p).exists():\n",
    "        data_path = p\n",
    "        break\n",
    "\n",
    "if data_path is None:\n",
    "    raise FileNotFoundError(\"CSV not found. Update POSSIBLE_PATHS with correct path.\")\n",
    "\n",
    "df = pd.read_csv(data_path, low_memory=False)\n",
    "print(\"Loaded rows:\", len(df))\n",
    "df.head(200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a17f6364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected rating column: stars\n"
     ]
    }
   ],
   "source": [
    "# Auto-detect rating column\n",
    "rating_cols = ['stars','rating','star','review_stars']\n",
    "rating_col = None\n",
    "for c in rating_cols:\n",
    "    if c in df.columns:\n",
    "        rating_col = c\n",
    "        break\n",
    "\n",
    "if rating_col is None:\n",
    "    # If not found, try numeric columns with 1-5 values\n",
    "    for c in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[c]):\n",
    "            unique_vals = set(df[c].dropna().unique())\n",
    "            if all(v in {1,2,3,4,5} for v in list(unique_vals)[:min(50,len(unique_vals))]):\n",
    "                rating_col = c\n",
    "                break\n",
    "\n",
    "if rating_col is None:\n",
    "    print(\"Couldn't auto-detect rating column. Please set rating_col manually.\")\n",
    "else:\n",
    "    print(\"Detected rating column:\", rating_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6285a97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected text column: text\n"
     ]
    }
   ],
   "source": [
    "# Text column detection\n",
    "text_cols = ['text','review','content','comments','review_text']\n",
    "text_col = None\n",
    "for c in text_cols:\n",
    "    if c in df.columns:\n",
    "        text_col = c\n",
    "        break\n",
    "if text_col is None:\n",
    "    # take first string-like column with long average length\n",
    "    string_cols = [c for c in df.columns if pd.api.types.is_string_dtype(df[c])]\n",
    "    if string_cols:\n",
    "        lengths = {c: df[c].dropna().astype(str).map(len).median() for c in string_cols}\n",
    "        text_col = max(lengths, key=lengths.get)\n",
    "print(\"Detected text column:\", text_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a671ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_ZERO_SHOT = \"\"\"\n",
    "You are a helpful assistant that reads a customer review and assigns a star rating from 1 to 5.\n",
    "Return ONLY a JSON object with two keys:\n",
    "- \"predicted_stars\": integer between 1 and 5\n",
    "- \"explanation\": short (1-2 sentences) reasoning why this rating was chosen.\n",
    "\n",
    "Example output:\n",
    "{{\"predicted_stars\": 4, \"explanation\":\"Reason here.\"}}\n",
    "\n",
    "Review:\n",
    "\\\"\\\"\\\"{review_text}\\\"\\\"\\\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "377894d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEW_SHOT_EXAMPLES = [\n",
    "    {\"review\":\"The food was amazing, staff super friendly, will come back!\", \"stars\":5},\n",
    "    {\"review\":\"Waited 1 hour for a table, rude host, food was cold.\", \"stars\":1},\n",
    "    {\"review\":\"Okay experience; some dishes were good, others average.\", \"stars\":3},\n",
    "    {\"review\":\"Great coffee but the croissant was stale and dry.\", \"stars\":3}\n",
    "]\n",
    "\n",
    "def build_few_shot_prompt(review_text, examples=FEW_SHOT_EXAMPLES):\n",
    "    examples_text = \"\"\n",
    "    for ex in examples:\n",
    "        examples_text += f\"Review: \\\"{ex['review']}\\\" -> Stars: {ex['stars']}\\n\"\n",
    "    prompt = f\"\"\"\n",
    "You are a helpful assistant. Use the examples below to decide the star rating (1-5) for a review.\n",
    "Return ONLY JSON: {{'predicted_stars': int, 'explanation': str}}.\n",
    "\n",
    "Examples:\n",
    "{examples_text}\n",
    "\n",
    "Now rate this review:\n",
    "\\\"\\\"\\\"{review_text}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afb508cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_RULE_BASED = \"\"\"\n",
    "You must assign a star rating 1-5 to the given review using this rubric:\n",
    "- 5 stars: glowing praise, multiple positive aspects, explicit 'best' or 'highly recommend'\n",
    "- 4 stars: mostly positive, minor issues\n",
    "- 3 stars: mixed or average experiences\n",
    "- 2 stars: negative overall with some redeeming quality\n",
    "- 1 star: strongly negative, major problems\n",
    "\n",
    "Return EXACTLY valid JSON (no extra text):\n",
    "{{\"predicted_stars\": <int 1-5>, \"explanation\": \"<1-2 sentence justification>\" }}\n",
    "\n",
    "If uncertain, choose the lower rating.\n",
    "Review:\n",
    "\\\"\\\"\\\"{review_text}\\\"\\\"\\\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce103898",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_COT = \"\"\"\n",
    "You are asked to reason about the review. First, think step-by-step about the sentiment and key points (do NOT output these thoughts).\n",
    "Then output ONLY valid JSON:\n",
    "{{\"predicted_stars\": <int 1-5>, \"explanation\": \"<short reasoning>\"}}.\n",
    "\n",
    "Review:\n",
    "\\\"\\\"\\\"{review_text}\\\"\\\"\\\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a0988e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def call_openai_chat(messages, model=\"gpt-4o\", max_tokens=200, temperature=0.0):\n",
    "    import openai\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if api_key is None:\n",
    "        raise ValueError(\"Set OPENAI_API_KEY in environment.\")\n",
    "    openai.api_key = api_key\n",
    "    resp = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return resp['choices'][0]['message']['content']\n",
    "\n",
    "def call_openrouter(prompt, model=\"gpt-4o-mini\", max_tokens=200, temperature=0.0):\n",
    "    # Example using OpenRouter's chat completions endpoint\n",
    "    api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "    if api_key is None:\n",
    "        raise ValueError(\"Set OPENROUTER_API_KEY in environment.\")\n",
    "    url = \"https://api.openrouter.ai/v1/chat/completions\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\":\"user\",\"content\": prompt}],\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature\n",
    "    }\n",
    "    r = requests.post(url, headers=headers, json=payload, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    return data[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "def call_gemini(prompt, model=\"gemini-1.0\", max_tokens=200, temperature=0.0):\n",
    "    # Generic example via HTTP — adjust for actual Gemini API/SDK\n",
    "    api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if api_key is None:\n",
    "        raise ValueError(\"Set GEMINI_API_KEY in environment.\")\n",
    "    # Placeholder URL — update per Gemini docs\n",
    "    url = \"https://api.gemini.google/v1/...\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "    payload = {\"prompt\": prompt, \"model\": model, \"max_tokens\": max_tokens}\n",
    "    r = requests.post(url, headers=headers, json=payload, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    return data[\"choices\"][0][\"text\"]\n",
    "\n",
    "def call_llm(prompt, provider=LLM_PROVIDER, **kwargs):\n",
    "    if provider == 'openai':\n",
    "        messages = [{\"role\":\"user\",\"content\": prompt}]\n",
    "        return call_openai_chat(messages=messages, **kwargs)\n",
    "    elif provider == 'openrouter':\n",
    "        return call_openrouter(prompt, **kwargs)\n",
    "    elif provider == 'gemini':\n",
    "        return call_gemini(prompt, **kwargs)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown provider. Choose 'openai','openrouter' or 'gemini'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8839899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import JSONDecodeError\n",
    "\n",
    "EXPECTED_SCHEMA = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"predicted_stars\": {\"type\": \"integer\", \"minimum\":1, \"maximum\":5},\n",
    "        \"explanation\": {\"type\":\"string\"}\n",
    "    },\n",
    "    \"required\": [\"predicted_stars\",\"explanation\"],\n",
    "    \"additionalProperties\": False\n",
    "}\n",
    "validator = Draft7Validator(EXPECTED_SCHEMA)\n",
    "\n",
    "def extract_json(text):\n",
    "    \"\"\"\n",
    "    Try common strategies to extract JSON from text:\n",
    "    1. Try direct json.loads\n",
    "    2. Find first { ... } and attempt to load\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return None, \"not string\"\n",
    "\n",
    "    # direct\n",
    "    try:\n",
    "        obj = json.loads(text)\n",
    "        return obj, None\n",
    "    except JSONDecodeError:\n",
    "        pass\n",
    "\n",
    "    # find first {...}\n",
    "    start = text.find(\"{\")\n",
    "    end = text.rfind(\"}\")\n",
    "    if start != -1 and end != -1 and end > start:\n",
    "        candidate = text[start:end+1]\n",
    "        try:\n",
    "            obj = json.loads(candidate)\n",
    "            return obj, None\n",
    "        except JSONDecodeError as e:\n",
    "            return None, f\"json decode error: {str(e)}\"\n",
    "    return None, \"no json found\"\n",
    "\n",
    "def validate_json_obj(obj):\n",
    "    if obj is None:\n",
    "        return False, \"null\"\n",
    "    errors = [e.message for e in validator.iter_errors(obj)]\n",
    "    if errors:\n",
    "        return False, \"; \".join(errors)\n",
    "    return True, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f90d8614",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_FUNS = {\n",
    "    \"zero_shot\": lambda text: PROMPT_ZERO_SHOT.format(review_text=text),\n",
    "    \"few_shot\": lambda text: build_few_shot_prompt(text),\n",
    "    \"rule_based\": lambda text: PROMPT_RULE_BASED.format(review_text=text),\n",
    "    \"cot\": lambda text: PROMPT_COT.format(review_text=text)\n",
    "}\n",
    "\n",
    "def run_batch(sample_df, prompt_key, provider=LLM_PROVIDER, max_calls=None, sleep_between=1.0):\n",
    "    results = []\n",
    "    rows = sample_df.to_dict('records')\n",
    "    if max_calls is None:\n",
    "        max_calls = len(rows)\n",
    "    for i, row in enumerate(tqdm(rows[:max_calls])):\n",
    "        review = row['text']\n",
    "        true_star = int(row['stars'])\n",
    "        prompt = PROMPT_FUNS[prompt_key](review)\n",
    "        try:\n",
    "            resp_text = call_llm(prompt, provider=provider, max_tokens=200, temperature=0.0)\n",
    "        except Exception as e:\n",
    "            resp_text = f\"__LLM_ERROR__: {str(e)}\"\n",
    "        parsed, parse_err = extract_json(resp_text)\n",
    "        valid, val_err = validate_json_obj(parsed)\n",
    "        pred_star = parsed.get('predicted_stars') if valid else None\n",
    "        results.append({\n",
    "            \"index\": i,\n",
    "            \"review_text\": review,\n",
    "            \"true_stars\": true_star,\n",
    "            \"raw_response\": resp_text,\n",
    "            \"parsed_json\": parsed,\n",
    "            \"parse_error\": parse_err,\n",
    "            \"json_valid\": valid,\n",
    "            \"json_validation_error\": val_err,\n",
    "            \"predicted_stars\": pred_star\n",
    "        })\n",
    "        time.sleep(sleep_between)  # be polite with rate limits\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "605c8341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'date', 'review_id', 'stars', 'text', 'type', 'user_id',\n",
       "       'cool', 'useful', 'funny'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a4df088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 200/200 [02:55<00:00,  1.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>review_text</th>\n",
       "      <th>true_stars</th>\n",
       "      <th>raw_response</th>\n",
       "      <th>parsed_json</th>\n",
       "      <th>parse_error</th>\n",
       "      <th>json_valid</th>\n",
       "      <th>json_validation_error</th>\n",
       "      <th>predicted_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Hipster,Trendy\" ????-I think NOT !!!! Very di...</td>\n",
       "      <td>1</td>\n",
       "      <td>__LLM_ERROR__: Set OPENAI_API_KEY in environment.</td>\n",
       "      <td>None</td>\n",
       "      <td>no json found</td>\n",
       "      <td>False</td>\n",
       "      <td>null</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>My husband &amp; I have been going to one Zipp's o...</td>\n",
       "      <td>4</td>\n",
       "      <td>__LLM_ERROR__: Set OPENAI_API_KEY in environment.</td>\n",
       "      <td>None</td>\n",
       "      <td>no json found</td>\n",
       "      <td>False</td>\n",
       "      <td>null</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Perfect place for a hot summer day.  Amazing p...</td>\n",
       "      <td>5</td>\n",
       "      <td>__LLM_ERROR__: Set OPENAI_API_KEY in environment.</td>\n",
       "      <td>None</td>\n",
       "      <td>no json found</td>\n",
       "      <td>False</td>\n",
       "      <td>null</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                        review_text  true_stars  \\\n",
       "0      0  \"Hipster,Trendy\" ????-I think NOT !!!! Very di...           1   \n",
       "1      1  My husband & I have been going to one Zipp's o...           4   \n",
       "2      2  Perfect place for a hot summer day.  Amazing p...           5   \n",
       "\n",
       "                                        raw_response parsed_json  \\\n",
       "0  __LLM_ERROR__: Set OPENAI_API_KEY in environment.        None   \n",
       "1  __LLM_ERROR__: Set OPENAI_API_KEY in environment.        None   \n",
       "2  __LLM_ERROR__: Set OPENAI_API_KEY in environment.        None   \n",
       "\n",
       "     parse_error  json_valid json_validation_error predicted_stars  \n",
       "0  no json found       False                  null            None  \n",
       "1  no json found       False                  null            None  \n",
       "2  no json found       False                  null            None  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "sample_df = df.copy()\n",
    "# test\n",
    "test_results = run_batch(\n",
    "    sample_df.sample(200, random_state=1),\n",
    "    prompt_key='few_shot',\n",
    "    provider=LLM_PROVIDER,\n",
    "    max_calls=200,\n",
    "    sleep_between=0.8\n",
    ")\n",
    "\n",
    "test_results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08512bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batch(df, prompt_key, provider, max_calls=10, sleep_between=1.0):\n",
    "    # your implementation here\n",
    "    ...\n",
    "import time\n",
    "\n",
    "def run_batch(df, prompt_key, provider, max_calls=10, sleep_between=1.0):\n",
    "    results = []\n",
    "\n",
    "    for i in range(min(max_calls, len(df))):\n",
    "        row = df.iloc[i]\n",
    "\n",
    "        # ---- Replace this with your actual LLM call ----\n",
    "        response = f\"Dummy output for {prompt_key}\"\n",
    "        # ------------------------------------------------\n",
    "\n",
    "        results.append({\n",
    "            \"input\": row.to_dict(),\n",
    "            \"prompt\": prompt_key,\n",
    "            \"provider\": provider,\n",
    "            \"output\": response\n",
    "        })\n",
    "\n",
    "        time.sleep(sleep_between)\n",
    "\n",
    "    import pandas as pd\n",
    "    return pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eceb47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot prompt\n",
    "def zero_shot_prompt(text):\n",
    "    return f\"Read the following review and predict the star rating (1 to 5):\\n\\n{text}\\n\\nAnswer with only a number.\"\n",
    "\n",
    "# Few-shot prompt\n",
    "def few_shot_prompt(text):\n",
    "    examples = \"\"\"\n",
    "Example 1:\n",
    "Review: \"Amazing product! Works perfectly.\"\n",
    "Stars: 5\n",
    "\n",
    "Example 2:\n",
    "Review: \"Terrible, broke in one day.\"\n",
    "Stars: 1\n",
    "\"\"\"\n",
    "    return examples + f\"\\nNow predict for this review:\\n{text}\\nAnswer with only a number.\"\n",
    "\n",
    "# Rule-based prompt\n",
    "def rule_based_prompt(text):\n",
    "    return f\"\"\"\n",
    "Use these rules:\n",
    "- Positive words → higher stars\n",
    "- Negative words → lower stars\n",
    "- Mix of both → 3 stars\n",
    "Review: {text}\n",
    "Predict stars (1–5). Only number.\n",
    "\"\"\"\n",
    "\n",
    "# Chain-of-thought (CoT)\n",
    "def cot_prompt(text):\n",
    "    return f\"\"\"\n",
    "Think step by step about the sentiment of this review:\n",
    "{text}\n",
    "Then give final star rating (1–5). Only number.\n",
    "\"\"\"\n",
    "\n",
    "# Dictionary of prompt creators\n",
    "PROMPT_FUNS = {\n",
    "    \"zero_shot\": zero_shot_prompt,\n",
    "    \"few_shot\": few_shot_prompt,\n",
    "    \"rule_based\": rule_based_prompt,\n",
    "    \"cot\": cot_prompt\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e5cd051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (2.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from openai) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from openai) (2.12.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!\"{sys.executable}\" -m pip install openai\n",
    "# AIzaSyCBcEg-W_3krF1QvbhZkwG3zRtwoGVckjk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b8a1430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!\"{sys.executable}\" -m pip install -q google-generativeai\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyCBcEg-W_3krF1QvbhZkwG3zRtwoGVckjk\")   # paste your key here\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f080d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(prompt, provider=\"gemini\"):\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "LLM_PROVIDER = \"gemini\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9138b786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (0.8.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from google-generativeai) (2.25.2)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from google-generativeai) (2.187.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from google-generativeai) (2.43.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: pydantic in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from google-generativeai) (2.12.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from google-generativeai) (4.15.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from google-api-core->google-generativeai) (1.72.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from google-api-core->google-generativeai) (2.32.5)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from google-auth>=2.15.0->google-generativeai) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.11.12)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from pydantic->google-generativeai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from pydantic->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from tqdm->google-generativeai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e69c9f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (8.1.8)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from ipywidgets) (9.8.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from ipywidgets) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from ipywidgets) (3.0.16)\n",
      "Requirement already satisfied: colorama>=0.4.4 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator>=4.3.2 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from jedi>=0.18.1->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\samta sakha\\appdata\\roaming\\python\\python314\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7366ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77d5f7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports & setup\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyCBcEg-W_3krF1QvbhZkwG3zRtwoGVckjk\")\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "def call_llm(prompt):\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d5d496",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "393f7e89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GEMINI_MODEL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Assuming GEMINI_MODEL is defined, e.g., GEMINI_MODEL = \"gemini-1.5-flash\"\u001b[39;00m\n\u001b[32m      5\u001b[39m genai.GenerativeModel(\u001b[33m\"\u001b[39m\u001b[33mmodels/gemini-1.5-flash-latest\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_gemini\u001b[39m(prompt: \u001b[38;5;28mstr\u001b[39m, model: \u001b[38;5;28mstr\u001b[39m = \u001b[43mGEMINI_MODEL\u001b[49m, max_output_tokens: \u001b[38;5;28mint\u001b[39m = \u001b[32m200\u001b[39m, temperature: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m0.0\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     10\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[33;03m    Call Gemini and return the assistant text response.\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[33;03m    Uses the modern 'generate_content' style with fallbacks.\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     15\u001b[39m         \u001b[38;5;66;03m# Modern API call\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'GEMINI_MODEL' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Assuming GEMINI_MODEL is defined, e.g., GEMINI_MODEL = \"gemini-1.5-flash\"\n",
    "genai.GenerativeModel(\"models/gemini-1.5-flash-latest\")\n",
    "\n",
    "\n",
    "\n",
    "def call_gemini(prompt: str, model: str = GEMINI_MODEL, max_output_tokens: int = 200, temperature: float = 0.0) -> str:\n",
    "    \"\"\"\n",
    "    Call Gemini and return the assistant text response.\n",
    "    Uses the modern 'generate_content' style with fallbacks.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Modern API call\n",
    "        model_obj = genai.GenerativeModel(model)\n",
    "        generation_config = genai.types.GenerationConfig(max_output_tokens=max_output_tokens, temperature=temperature)\n",
    "        resp = model_obj.generate_content(prompt, generation_config=generation_config)\n",
    "        \n",
    "        # Extract text\n",
    "        if hasattr(resp, \"text\"):\n",
    "            return resp.text\n",
    "        elif isinstance(resp, dict) and \"candidates\" in resp and resp[\"candidates\"]:\n",
    "            candidate = resp[\"candidates\"][0]\n",
    "            if \"content\" in candidate and \"parts\" in candidate[\"content\"] and candidate[\"content\"][\"parts\"]:\n",
    "                return candidate[\"content\"][\"parts\"][0][\"text\"]\n",
    "        # Fallback to JSON dump\n",
    "        return json.dumps(resp)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Gemini call failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b463ee5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001\n",
      "models/gemini-2.5-flash\n",
      "models/gemini-2.5-pro\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "models/gemma-3n-e2b-it\n",
      "models/gemini-flash-latest\n",
      "models/gemini-flash-lite-latest\n",
      "models/gemini-pro-latest\n",
      "models/gemini-2.5-flash-lite\n",
      "models/gemini-2.5-flash-image-preview\n",
      "models/gemini-2.5-flash-image\n",
      "models/gemini-2.5-flash-preview-09-2025\n",
      "models/gemini-2.5-flash-lite-preview-09-2025\n",
      "models/gemini-3-pro-preview\n",
      "models/gemini-3-pro-image-preview\n",
      "models/nano-banana-pro-preview\n",
      "models/gemini-robotics-er-1.5-preview\n",
      "models/gemini-2.5-computer-use-preview-10-2025\n",
      "models/deep-research-pro-preview-12-2025\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/gemini-embedding-001\n",
      "models/aqa\n",
      "models/imagen-4.0-generate-preview-06-06\n",
      "models/imagen-4.0-ultra-generate-preview-06-06\n",
      "models/imagen-4.0-generate-001\n",
      "models/imagen-4.0-ultra-generate-001\n",
      "models/imagen-4.0-fast-generate-001\n",
      "models/veo-2.0-generate-001\n",
      "models/veo-3.0-generate-001\n",
      "models/veo-3.0-fast-generate-001\n",
      "models/veo-3.1-generate-preview\n",
      "models/veo-3.1-fast-generate-preview\n",
      "models/gemini-2.5-flash-native-audio-latest\n",
      "models/gemini-2.5-flash-native-audio-preview-09-2025\n",
      "models/gemini-2.5-flash-native-audio-preview-12-2025\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyCBcEg-W_3krF1QvbhZkwG3zRtwoGVckjk\")\n",
    "\n",
    "models = genai.list_models()\n",
    "\n",
    "for m in models:\n",
    "    print(m.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62bfa371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"rating_score\": 5,\n",
      "  \"rating_max\": 5,\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"keywords\": [\"food\", \"amazing\"],\n",
      "  \"summary\": \"Excellent food quality and taste.\",\n",
      "  \"detailed_breakdown\": {\n",
      "    \"food_quality\": 5,\n",
      "    \"taste\": 5,\n",
      "    \"overall_satisfaction\": 5\n",
      "  }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Configure your API key\n",
    "genai.configure(api_key=\"AIzaSyCBcEg-W_3krF1QvbhZkwG3zRtwoGVckjk\")\n",
    "\n",
    "# Use a model that your account supports\n",
    "MODEL_NAME = \"models/gemini-2.5-flash\"\n",
    "\n",
    "model = genai.GenerativeModel(MODEL_NAME)\n",
    "\n",
    "def call_llm(prompt):\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "print(call_llm(\"Give JSON rating for: The food was amazing!\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6fce3370",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFound",
     "evalue": "404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFound\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m     response = model.generate_content(prompt)\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.text\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcall_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGive JSON rating for: The food was amazing!\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mcall_llm\u001b[39m\u001b[34m(prompt)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_llm\u001b[39m(prompt):\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     response = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.text\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\google\\generativeai\\generative_models.py:331\u001b[39m, in \u001b[36mGenerativeModel.generate_content\u001b[39m\u001b[34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[39m\n\u001b[32m    329\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_iterator(iterator)\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_response(response)\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.InvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:835\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    834\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m835\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\google\\api_core\\retry\\retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\google\\api_core\\retry\\retry_unary.py:156\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     next_sleep = \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[32m    167\u001b[39m     time.sleep(next_sleep)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\google\\api_core\\retry\\retry_base.py:214\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[32m    209\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    210\u001b[39m         error_list,\n\u001b[32m    211\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    212\u001b[39m         original_timeout,\n\u001b[32m    213\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    216\u001b[39m     on_error_fn(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\google\\api_core\\retry\\retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\google\\api_core\\timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\google\\api_core\\grpc_helpers.py:77\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(*args, **kwargs)\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mNotFound\u001b[39m: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods."
     ]
    }
   ],
   "source": [
    "# wrong\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyCBcEg-W_3krF1QvbhZkwG3zRtwoGVckjk\")\n",
    "\n",
    "MODEL_NAME = \"models/gemini-1.5-flash-latest\"\n",
    "\n",
    "model = genai.GenerativeModel(MODEL_NAME)\n",
    "\n",
    "def call_llm(prompt):\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "print(call_llm(\"Give JSON rating for: The food was amazing!\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72734e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK1_PROMPT = \"\"\"\n",
    "You are an AI that evaluates customer reviews.\n",
    "\n",
    "Return ONLY a valid JSON object with:\n",
    "\n",
    "{\n",
    "  \"rating\": integer (1–5),\n",
    "  \"justification\": \"short explanation\"\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- Output MUST be only JSON.\n",
    "- No extra text, no comments.\n",
    "- Keep justification short.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b21b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(review: str):\n",
    "    prompt = TASK1_PROMPT + f\"\\n\\nReview: {review}\"\n",
    "    output = call_llm(prompt)\n",
    "\n",
    "    # Ensure pure JSON\n",
    "    try:\n",
    "        return json.loads(output)\n",
    "    except:\n",
    "        # Fix common model errors\n",
    "        cleaned = output.strip().strip(\"```json\").strip(\"```\")\n",
    "        return json.loads(cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb23bc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "124fa2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def call_llm(prompt):\n",
    "    response = model.generate_content(prompt)\n",
    "    time.sleep(2)  # 2-second delay to avoid rate limit\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a15f43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rating': 3, 'justification': 'fallback due to error: Expecting value: line 1 column 1 (char 0)'}\n"
     ]
    }
   ],
   "source": [
    "print(predict_rating(\"The food was amazing but delivery was late!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2fd59491",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"rating\": {\"type\": \"integer\", \"minimum\": 1, \"maximum\": 5},\n",
    "        \"justification\": {\"type\": \"string\"}\n",
    "    },\n",
    "    \"required\": [\"rating\", \"justification\"]\n",
    "}\n",
    "\n",
    "validator = Draft7Validator(rating_schema)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "465eacc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_json(data):\n",
    "    errors = sorted(validator.iter_errors(data), key=lambda e: e.path)\n",
    "    return len(errors) == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7db0461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task1_predict(review: str):\n",
    "    json_output = predict_rating(review)\n",
    "\n",
    "    if validate_json(json_output):\n",
    "        return json_output\n",
    "    else:\n",
    "        # fallback if LLM gives slight errors\n",
    "        return {\n",
    "            \"rating\": json_output.get(\"rating\", 3),\n",
    "            \"justification\": json_output.get(\"justification\", \"Model fallback\")\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "46ee4efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "from jsonschema import Draft7Validator\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyCBcEg-W_3krF1QvbhZkwG3zRtwoGVckjk\")\n",
    "\n",
    "MODEL_NAME = \"models/gemini-2.5-flash\"\n",
    "model = genai.GenerativeModel(MODEL_NAME)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7734594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"rating\": {\"type\": \"integer\", \"minimum\": 1, \"maximum\": 5},\n",
    "        \"justification\": {\"type\": \"string\"}\n",
    "    },\n",
    "    \"required\": [\"rating\", \"justification\"]\n",
    "}\n",
    "\n",
    "validator = Draft7Validator(rating_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d520dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(review_text: str):\n",
    "    prompt = f\"\"\"\n",
    "    You are a JSON-only model. \n",
    "    Rate the following review from 1 to 5 stars.\n",
    "    Return ONLY valid JSON:\n",
    "    {{\n",
    "        \"rating\": <1-5>,\n",
    "        \"justification\": \"<short reason>\"\n",
    "    }}\n",
    "\n",
    "    Review: \"{review_text}\"\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        raw = response.text\n",
    "\n",
    "        # Parse JSON\n",
    "        json_data = json.loads(raw)\n",
    "\n",
    "        return json_data\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"rating\": 3, \"justification\": f\"fallback due to error: {e}\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "57244b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task1_predict(review_text: str):\n",
    "    data = predict_rating(review_text)\n",
    "\n",
    "    errors = sorted(validator.iter_errors(data), key=lambda e: e.path)\n",
    "\n",
    "    if errors:\n",
    "        return {\n",
    "            \"rating\": data.get(\"rating\", 3),\n",
    "            \"justification\": data.get(\"justification\", \"fallback schema fix\")\n",
    "        }\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5abb9057",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df.sample(200, random_state=1)\n",
    "\n",
    "df_small[\"model_output\"] = df_small[\"text\"].apply(task1_predict)\n",
    "df_small[\"model_rating\"] = df_small[\"model_output\"].apply(lambda x: x[\"rating\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4d8515e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"model_output\"] = df[\"text\"].apply(task1_predict)\n",
    "df[\"model_rating\"] = df[\"model_output\"].apply(lambda x: x[\"rating\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c92264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def validate_output(model_output):\n",
    "    if not isinstance(model_output, dict):\n",
    "        return False\n",
    "    if \"rating\" not in model_output:\n",
    "        return False\n",
    "    if not isinstance(model_output[\"rating\"], int):\n",
    "        return False\n",
    "    if not (1 <= model_output[\"rating\"] <= 5):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "df[\"is_valid\"] = df[\"model_output\"].apply(validate_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d2a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import pandas as pd\n",
    "#df = pd.read_csv(r\"C:\\Users\\Samta sakha\\OneDrive\\Desktop\\projects2\\Fynd\\yelp.csv.zip\")\n",
    "\n",
    "#df[\"model_output\"] = df[\"text\"].apply(task1_predict)\n",
    "#df[\"model_rating\"] = df[\"model_output\"].apply(lambda x: x[\"rating\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ded8323f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  My wife took me here on my birthday for breakf...   \n",
      "1  I have no idea why some people give bad review...   \n",
      "2  love the gyro plate. Rice is so good and I als...   \n",
      "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...   \n",
      "4  General Manager Scott Petello is a good egg!!!...   \n",
      "\n",
      "                                        model_output  model_rating  \n",
      "0  {'rating': 3, 'justification': 'fallback due t...             3  \n",
      "1  {'rating': 3, 'justification': 'fallback due t...             3  \n",
      "2  {'rating': 3, 'justification': 'fallback due t...             3  \n",
      "3  {'rating': 3, 'justification': 'fallback due t...             3  \n",
      "4  {'rating': 3, 'justification': 'fallback due t...             3  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df[[\"text\", \"model_output\", \"model_rating\"]].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8a7dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5ad393",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
